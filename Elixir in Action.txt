Chapter 1 First Steps (3)
    1.1 About Erlang
        
        1.1.1 High Availability

        1.1.2 Erlang concurrency
            Fault Tolerance
            Scalability
            Distribution
            Responsiveness

        1.1.3 Server-side Systems

        1.1.4 The Development Platform
            Open Telecom Platform:
                concurrency and Distribution patterns
                Error Detection and recovery
                Packaging code into libraries
                Systems deployment
                Live Code Updates
        
        1.1.5 Relationship to Microservices
            A Service for this section is a part of the system running in a separate OS
            With this we can distribute the service to many different machine and then avoid the entire machine going down when 1 fails.
            One of the issues arises when you want to completely separate the service, you might still have issues with keeping it completely separate.
        
    1.2 About Elixir

        1.2.1 Code Simplification
            One of the benefits from Erlang to Elixir if the reduction of boiler plate code that doesn't need to be there.
                defmodule SumServer do
                    use GenServer
                    def start do
                        GenServer.start(__MODULE__, nil)
                    end
                    def sum(server, a, b) do
                        GenServer.call(server, {:sum, a, b})
                    end
                    def handle_call({:sum, a, b}, _from, state) do
                        {:reply, a + b, state}
                    end
                end

        1.2.2 Composing Functions
            Pipe Operator is the glue that takes one form of data and can turn it into an other type or style.

        1.2.3 The Big Picture

    1.3 Disadvantages
    
        1.3.1 Speed
            It will be "slower" but Elixir makes up for it. The scheduler will take care of any issues and will just make the overall system slower if there is any issue with hardware, IT WONT JUST STOP.

        1.3.2 Ecosystem

Chapter 2 Building Blocks (19)

    2.1 The Interactive Shell
        iex # starts the Interactive shell
        Also keep in mind that everything returns a value if, when, for, while, enum etc
        Line breaks are the end of expression as long as they are valid that is.
        ctrl-c twice breaks the shell

    2.2 Working with variables
        Elixir uses dynamic bindings
        Only use lowercase letters with underscores for more than 1 word variables
        Remember that you are not mutating a variable you are creating a new variable and rebinding the location.

    2.3 Organizing your Code
        Use many small functions

        2.3.1 Modules
             A module is a collection of functions 

             To define a module you will need to to use the defmodule Name do
             To use the module you can type everything into the shell or use:
                iex module.file.ex # This will load the script into the shell as well.

                You can create more than 1 in a file and you can nest them as well

        2.3.2 Functions
            ? returns true/false
            ! indicates it might raise a error

            defmodule and def are MACROS

            You can omit the parenthesis when calling a function buts its not recommended

            |> Pipe Operator will place the output of the previous function into the FIRST param of the next

        2.3.3 Function Arity
            This is the number of arguments a function will take. You can use the \\ to define default values for a param
        
        2.3.4 Function Visibility
            Functions are by default exported unless you use the defp macro
        
        2.3.5 Imports and Aliases
            import # This will allow you to import other modules into your code.
            alias mod, as: MyIO # This will import a new module but give it a nickname

            If you don't use the syntax , as: ... 
            whatever you have after a . will be used.
        
        2.3.6 Module Attributes
            @pi some_info
            @radius 2

            These can be used as compile-time constants and can be referenced with 
            @pi

            @moduledoc and @doc can be used to fetch docs for the functions if you create and use them
                Code.fetch_docs(function_name)

                You can even use h function_name within the shell

            Type Specifications
                or typespecs are used to determine what the input and output of a function is.
                @spec function_name(number) :: number
        
        2.3.7 Comments
            # Comments start with the # in Elixir

    2.4 Understanding the Type System
        2.4.1 Numbers
            / # will always return a float trunc will get rid of the .0000
            div and rem will return ints
            _ can act as delimiters for large numbers 1_000_000 == 1000000

        2.4.2 Atoms
            These are literally named constants
            You can use spaces as such :"an atom with spaces"
            What is nice about atoms is that they are just kept within a atom table so you can keep the resources low

            Aliases
                Using an uppercase letter to start will create an atom as well
                AnAtom == :"Elixir.AnAtom"

                TO go a bit further this is the same thing as the alias when you import
                    alias IO, as: MyIO
                    MyIO == Elixir.IO
                
            Atoms and Booleans
                :true == true and :false == false
            
            Nil and Truthy Values
                :nil ~- null
                nil == false and everything else it true

                || returns any value that isn't falsy
                If you sting a bunch of || together you will just get the last value if everything is false

                && returns the second expression if the first is truthy otherwise it returns the first expression

                SO you can string || to get any value that any value that exists

                Or you an string && to check if the first value is true and retrieve the second
        
        2.4.3 Tuples
            To access a tuples element you can use elem(tuple, 1) # where the tuple is a tuple and the 1 is the index of the tuple you want.

            put_elem(tuple, index, value)

            Remember that you will never modify anything in Elixir you must always redefine the variable or pass the new one on

        2.4.4 Lists
            Keep in mind that it is easy to retrieve the first element of a list and harder for the next and so on. It is a value and a reference to the next element in the list.

            One of the basic ways to get an element is to use the Enum.at(list, index)

            Also there is the 'in' that will check to see if the list contains what you are passing to it
                5 in [2, 3, 4, 5]
                true

            List.replace_at(list, index, value)

            List.insert_at(list, index, value) # you can always use the -1 to append to the end of a list

            Recursive List Definition
                There is a great way to think about lists and that is with the head/tail representation

                list = [head | tail] # with this head is a single element and tail is the rest 
                list = [head | second | tail] # same with this head = single second = single tail = rest

                Think of lists as pairs, and element and a list, if you want to not use the above syntax you can use hd() or tl() # head or tail in this case

        2.4.5 Immutability
            Remember that elixir is immutable so you must always rebind a variable

            Modifying Tuples
                Modifying a tuple or anything really will create a shallow copy of the first bit of data and then do the work to it, if you rebind it the old data wont have a reference and be dealt with by the garbage collector after the operation.
            
            Modifying Lists
                So for lists you will create a shallow copy of the list up to the element that you want to change and the rest of the list will not be changed or copied as any lists is just element and a reference to the rest of the list.

            Benefits
                One of the best things about Immutability is that there is no side effects, IE you know what will change no matter what and if you want to change something you must implicitly do that thing.

                The one thing to keep in mind is that anything that you do to other databases will be permanent

        2.4.6 Maps
            These are key and value pairs

            Dynamically Sized Maps
                %{} is an empty map
                
                There are a few ways to make a map 
                squares = %{1 => 2, 2 => 4}
                squares = Map.new([{1, 1}, {2, 2}, {3, 3}])

                And then you can retrieve the elements with
                squares[1] # with the value that is in the [] is the :atom/key of the element not the index
                Map.get(map, key) # will also work
                Map.get(map, key, :default) # this is different as you can set the default not found value that will be returned

                Map.fetch(map, key) # This will return a tuple with {:ok, value} or :error if not found
                Map.fetch!(map, key) will only work if the value exists and crash if not

            Structured Data
                What is nice about maps is that you can access any amount of data and change anything that you want within the map.

                %{old_map | key: change, key2: change} # this will change the values for key: and key2: only if they exist

                With this being said it is best to create a map with all the keys present and then modify them as needed nil can be the default value until you know what you want in the field

        2.4.7 Binaries and Bitstrings
            A binary is a chunk of bytes. You can create binaries by enclosing a sequence with << >> it will only store the byte up to 256 anything higher will result in the rem of the number. However you can denote the amount of bits to use with :: so <<257::16>> 
            <<1,1>> # This expression places the number 257 into 16 bits of consecutive memory space. The output indicates that you use 2 bytes, both with a value of 1

            <> will concatenate bit strings or binaries

        2.4.8 Strings
            Binary Strings
                "This is a string" is the common way to represent a string
                #{} # This can embed elixir code within a string

                "You can also 
                    use multi line strings"

                ~s(this is also a string) # This is using sigils if you want to use quotes in the sigil you must escape them first.

                ~S(doesn't handle escaped characters\\n) # "doesn't handle escaped characters\\n"

                here docs is the last case and they use """ """

                same as with bit strings we can concatenate with <>

            Character Lists
                AKA charlist
                any list of integers that can be represented as characters can and will be seen as a charlist
                ~c"ABC" is also a way to get to a charlist
                'ABC' will also work

                String.to_charlist() will convert a string to a charlist
            
        2.4.9 First-Class Functions
            Within elixir we can assign a FUNCTION to a variable so in that case we are creating an anonymous function or a lambda

            once it is named you can use the (.) to call it with an input # This is because we want to differentiate the difference between a named function and the lambda.

            So if you want to use an Enum.each() you can set a function before and then pass a list and the function without describing the function in the Enum.each() call.

            Let's add and other bit of sugar: if you want to just skip the complete setting of a function you can use the &IO.puts/1 # This is the capture Operator.
                Where the & sets the function and then you can pass &1 &2 &3 etc where they will reference the first second and third argument that is passed.

            Closures
                A lambda can reference any variable outside it's scope. So with this you can keep a reference to any outside variable if the function is still held with a reference. This is called closure.

                Keep in mind once the closure is set changing the outside variable will NOT change the closure.
        
        2.4.10 Other Built-In Types
            A reference: Kernel.make_ref/0 this will only be saved for the instance that calls it

            a process identifier(PID): This is used for dealing with different processes

            the port identifier: IO is the communication tool.

        2.4.11 Higher-Level Types
            Range
                number..other_number # this will create a range from the number to an other_number
                These are also enumerable
            
            Keyword Lists
                This is usually set with days = [{:monday, 1}, {:tuesday, 2}] # but can be sorted to 
                    days= [monday: 1, tuesday: 2]

                The Keyword module is used in this case. Keep in mind this is still a list and complexity is still O(n) many different function will use this syntax to add additional options to a function.

            MapSet
                Use the MapSet module here and you can add in and store unique values, with the value being of any type.
            
            Times and Dates
                Here are some types that we can use here:
                    Date (~D), Time(~T), DateTime(~U), NaiveDateTime(~N).

                    Once you set the values you can call them with the (.) notation hour minute etc

        2.4.12 IO Lists
            This is used to forward output that will be send to and IO device
            iolist = [[[~c"He"], "llo,"], " work", "d!"] # This is just "Hello World!"

            What is nice is that you can incrementally set all the things you want sent
                iolist = []
                iolist = [iolist, "This"]
                iolist = [iolist, " is"]
                iolist = [iolist, " an"]
                iolist = [iolist, " IO list."] # This will append all the new things that will be sent

        2.5 Operators
            1 == 1.0 # weak Operator       true
            1 === 1.0 # strict Operator    false

            and, or, not

    2.6 Macros
        Lots of what helps to run elixir code is the macro. defmodule and def are parts of the macro they help to change the syntax of the code you write.

    2.7 Understanding the Runtime
        2.7.1 Modules and Functions in the Runtime
            Module Names and Atoms
                When you create a module you are in fact creating a file that will be run.

            Pure Erlang Modules
                Now let's talk about this syntax
                    :code.get_path

                Everything that y=ou create will spawn a file with the name xyz.beam  and they will correspond to an atom

            Dynamically calling Functions
                You can Dynamically call function with teh Kernel.apply/3
                This receives 3 arguments: the module atom, the function atom, and the list of arguments. Shortened to (MFA) 

        2.7.2 Starting the Runtime
            Interactive Shell
                This wont run as fast as a pure complied code so keep that in mind as it need to interpret the code first

            Running Scripts
                elixir my_source.ex # This will run through the following every time
                    Beam is started
                    File is compiled in memory
                    Whatever code resides outside of the module is interpreted
                    Once everything is finished the Beam is stopped.

                If you want to designate that it's a script file append s (exs) where the s stands for script

                So if we had:
                    defmodule MyModule do
                        def run do
                            IO.puts("Called MyModule.run")
                        end
                    end
                    MyModule.run

                If you want to make sure the BEAM doesn't stop on the end you can append --no-halt before the script name # elixir --no-halt script.exs

            The Mix tool
                This is used to make and use project made up of multiple source files.
                    mix new my_project
                    cd my_project
                    mix compile

                The compile goes through all the source files and places the resulting .beam files in the ebin folder

                You can execute functions with the 
                    mix run -e 

                You can also run test with the
                    mix test # This will find the test files and run them for you and let you know if there are issues

    Summary
         Elixir code is divided into modules and functions.
         Elixir is a dynamic language. The type of a variable is determined by the value it
        holds.
         Data is immutable—it can’t be modified. A function can return the modified
        version of the input that resides in another memory location. The modified ver-
        sion shares as much memory as possible with the original data.
         The most important primitive data types are numbers, atoms, and binaries.
         There is no Boolean type. Instead, the atoms true and false are used.
         There is no nullability. The atom nil can be used for this purpose.
         There is no string type. Instead, you can use either binaries (recommended) or
        lists (when needed).
         The built-in complex types are tuples, lists, and maps. Tuples are used to group
        a small, fixed-size number of fields. Lists are used to manage variable-size collections. A map is a key–value data structure.
         Range, keyword lists, MapSet, Date, Time, NaiveDateTime, and DateTime are abstractions built on top of the existing built-in types.
         Functions are first-class citizens.
         Module names are atoms (or aliases) that correspond to .beam files on the disk.
         There are multiple ways of starting programs: iex, elixir, and the mix tool.

Chapter 3 Control Flow (69)
    3.1 Pattern Matching
        We can start with the = (match Operator)
    
        3.1.1 The Match Operator
            We might at first think of this as an assignment but something more is going on. The left side is called the pattern and the right side is the expression.
        
        3.1.2 Matching Tuples
            {name, age} = {"Bob", 25} #  This is a form of pattern matching

            This is very useful if a function returns a tuple and you want to bind each bit of data to separate variable.

            We could even take some of the outputs and divide them further.

            There is also issues if the right and left sides don't match
                {name, age} = "can't match"
                ** (MatchError) no match of right hand side value: "can't match"

        3.1.3 Matching Constants
            1 = 1 # This is a valid elixir expression 
            quick side note when creating a tuple you can add an extra field in the beginning that will denote what kind of tuple you are making
                person = {:person, "bob", 25}

            Many times with elixir functions will return {:ok, value} or {:error, reason} lets look at this next line of code.
            {:ok, contents} = File.read("my_app.config")
                attempts to opens a file
                if successful file is extracted and then the contents are sent as contents
                if it fails error is raised and it will tell you the reason

            You this syntax to write better cases and help deal with bad results
        
        3.1.4 Variables in Patterns
            Anonymous variable is the (_) this will help you still pattern match but ignore data you don't need. You can even still have a descriptive name that will not issue a warning if not used.

            You can even nest pattern matching:
                {_, {hour, _, _}} = :calendar.local_time()

            What is nice is that you can even pattern match with the names of the variables
                 {value, value, value} = {127, 127, 127} # this works
                 {value, value, value} = {127, 127, 1}  # this doesn't work

            Sometimes you will want to pattern match against an already existing value, this is where the pin operator (^) comes in.
                expected = "bob"
                {^expected, _} = {"bob", 25}

                {^expected, _} = {"alice", 31}  # This will raise an error

            The ^ will be treated as if you hard coded the value as "bob"

        3.1.5 Matching Lists
            You can match to any element of a list
                [first, second, third] = [1, 2, 3]

                We could also use any of the above as well

            There is a common syntax for matching to elements of a list
            [head | tail] = [1, 2, 3]
            
            There is an elegant way of using matching and the pipe with min
                [min | _] = Enum.sort([3,2,1])
            Keep in mind that the hd() might be more elegant but this works as well

        3.1.6 Matching Maps
            The following is the general way that you would pattern match with a Map:
                %{name: name, age: age} = %{name: "Bob", age: 25}
            Keep in mind that when pattern matching with a Map you don't need to have every key on the left hand side
                %{age: age} = %{name: "Bob", age: 25}
            You will need to have the key present with the right hand side or you will be given an error
            
        3.1.7 Matching Bitstrings and Binaries
            You can pattern match with binaries as well
                iex(1)> binary = <<1, 2, 3>>
                <<1, 2, 3>>
                iex(2)> <<b1, b2, b3>> = binary
                <<1, 2, 3>>

            There is a way to match the first and then the rest of a binary
                iex(6)> <<b1, rest :: binary>> = binary
                <<1, 2, 3>>
            This states that the rest will be of an arbitrary bit size

            You can even separate then into specific sizes
            <<a :: 4, b :: 4>> = << 155 >>
            << 155 >>
            This says that we want then into four-bit sizes

            This is every helpful when trying to parse packed binary contents
        
            Matching Binary Strings
                Recall that strings are just binaries
                    <<b1, b2, b3>> = "ABC" # So you can take any string and break it into its parts

                That is great for any single character, but what about strings
                command = "ping www.site.com"
                "ping " <> url = command
        
        3.1.8 Compound Matches
            You can nest as you need any pattern matching
                [_, {name, _}, _] = [{"Bob", 25}, {"Alice", 30}, {"John", 35}] # or
                a = (b = 1 + 3)

            Now let's look at a better example
                {_, {hour, _, _}} = date_time = :calendar.local_time()
                Keep in mind that the pattern matching will only occur with the values that is not being omitted.

        3.1.9 General Behavior
            Pattern = term

    3.2 Matching with Functions
        This is one of the most powerful uses of pattern matching
            defmodule Rectangle do
                def area({a, b}) do
                    a * b
                end
            end 

        This just means that the param passed to the area function will be of the form {a, b}
        If you don't pass a tuple there will be an issue, you could then try and deal with the cases where you would not send a tuple and have more robustness

        3.2.1 Multiclause Functions
            What if you wanted to define a function that could take different shapes.
                rectangle = {:rectangle, 4, 5}
                square = {:square, 5}
                circle = {:circle, 4}

            defmodule Geometry do
                def area({:rectangle, a, b}) do
                    a * b
                end
            
                def area({:square, a}) do
                    a * a
                end
                def area({:circle, r}) do
                    r * r * 3.14
                end
            end 

            You can see in this case the pattern match will only call the right function if passed the right tuple. Keep in mind that you are creating a single function with clauses. In this way you can't just access one of the clauses. Recall the & that will capture a function. 

            fun = &Geometry.area/1

            What is nice about the clauses is that you can then create all the proper function clauses and then create a dummy function that will take anything else.
                def area(unknown) do
                    {:error, {:unknown_shape, unknown}}
                end

            This must go at the end as it will always try to go through the clauses from top to bottom and this will always pass. Also keep in mind that a function cares about Name and Arity.

        3.2.2 Guards
            This is helpful for when you want to be sure that you only call a function with the correct data type or values for the param.

            defmodule TestNum do
                def test(x) when x < 0 do
                    :negative
                end
                def test(x) when x == 0 do
                    :zero
                end
                def test(x) when x > 0 do
                    :positive
                end
            end

            This will test the number and only call the right function if the number is the right value.
            One thing to keep in mind is that elixir can compare different data types with this syntax
                number < atom < reference < fun < port < pid < tuple < map < list < bitstring (binary)

            With this in mind we see that a number is always the smallest and we can then extend the Guard to deal with that by adding # when is_number(x) and x > 0 and so on.

            Keep in mind that only certain operators can be called within a Guard:
                Comparison
                Boolean
                Arithmetic
                Type-check

            So last bit is that the error in a Guard will not return an error it will just make the Guard expression false and move on to an other function definition.

        3.2.3 Multiclause Lambdas
            You can use different clauses within a function definition to separate out the different inputs. This will also be used with Lambdas
                test_num =
                    fn
                        x when is_number(x) and x < 0 -> :negative
                        x when x == 0 -> :zero
                        x when is_number(x) and x > 0 -> :positive
                    end

            As you can see here we have different types of Guards within a lambda.
        
    3.3 Conditionals
        If and Case can be used for multicase conditionals. You can also use pattern matching to get a little bit more out of your functions.

        3.3.1 Branching with Multiclause Functions
            defmodule TestList do
                def empty?([]), do: true
                def empty?([_|_]), do: false
            end

            Then you can also use Guards for different data types.
                defmodule Polymorphic do
                    def double(x) when is_number(x), do: 2 * x
                    def double(x) when is_binary(x), do: x <> x
                end

            Recursion is a great example of multicase because you can set the base case with a static param.
                defmodule Fact do
                    def fact(0), do: 1
                    def fact(n), do: n * fact(n - 1)
                end
            Here we have the base case and then everything else falls from that. You can do a summation for a list with some of the same things.

        3.3.2 Classical Branching Expressions
            if, unless, cond, case are things that might be better than Multiclause as you will have to recreate the function with guards and still pass the proper param.

            If and Unless
                if condition do
                    ...
                else
                    ...
                end
                
                For the one liner we use
                    if cond, do: thing, else: other_thing
                Keep in mind that EVERYTHING in elixir will return a value

                unless result == :error, do: something_else

            cond
                cond do
                    expression_1 -> 
                        ...
                    expression_2 ->
                        ...
                    ...
                end
                These are used when you can't just pattern match with the value or you have different things to check against. You can also have a default case with the last one simply being true -> ...

            case
                case expression do
                    pattern_1 ->
                        ...
                    pattern_2 ->
                        ...
                    ...
                end
                The big difference here is that the expression has to pattern match with the expression. You can simply pass a variable that will be evaluated or you can make the expression something that will need to be evaluated. The default pattern will be _ ->

        3.3.3 The with Expression
            This is useful for when you want to chain a couple of expression and then return the error of the first expression that fails. You want to process registration data.

                %{
                "login" => "alice",
                "email" => "some_email",
                "password" => "password",
                "other_field" => "some_value",
                "yet_another_field" => "...",
                ...
                }
            
            We want to only worry about login:, email:, password: if you always have the right map it will never have an issue but what if you can't be sure that will happen. You want to return {:ok, result} or {:error, reason}

            If you were to use pattern matching and case to make sure that all the fields are right you might need to have nested cases and it might not look very good. However you can use with:
                with pattern_1 <- expression_1,
                    pattern_2 <- expression_2,
                    ...
                do
                    ...
                end

            For this you will go through each pattern and do the expression if all pass you go onto the do, if any fail the issue is returned as an error.

                def extract_user(user) do
                    with    {:ok, login} <- extract_login(user),
                            {:ok, email} <- extract_email(user),
                            {:ok, password} <- extract_password(user) do
                        {:ok, %{login: login, email: email, password: password}}
                    end
                end
    3.4 Loops and Iterations
        The principle looping structure in Elixir is Recursion.
        3.4.1 Iterating with Recursion
            With many of these examples we want to go through the list or numbers 1 by 1. You start at the "end" of the list and then go to the front recursively. That way you print the front then go back through the list.

        3.4.2 Tail Function Calls
            If the last thing a function does is call a function (or itself) then it's considered a Tail Function. Tail Recursion doesn't consume any more resources.

            defmodule ListHelper do
                def sum(list) do
                    do_sum(0, list)
                end
                defp do_sum(current_sum, []) do
                    current_sum
                end
                defp do_sum(current_sum, [head | tail]) do
                    new_sum = head + current_sum
                    do_sum(new_sum, tail)
                end
            end

            Recognizing Tail Calls
                So for this you must have only the call to an other function as the last line
                def fun(...) do
                    1 + another_fun(...)
                end # This is NOT a tail call as there is more than just a call to a function on the last line.

            Practice
                See the files that I add to the folder.

        3.4.3 Higher-Order Functions
            This is when you have a function that takes one for more functions as input or returns one or more functions.

            Enum.each/2 takes and enumerable and a lambda therefore it's a higher order function.
            Enum.map/2 is also a Higher order function.
                Enum.map(list, &(2 * &1)) # simplified lambda that uses &n to take the place of the nth argument

            Let's talk about filter for a second
                With this you can something like this
                case Enum.filter(
                            ["login", "email", "password"],  # Sets the different things to look for
                            &(not Map.has_key?(user, &1)) # Shorted Lambda to check a defined user
                        ) do
                    [] -> # Returns nothing if its not missing as we check not has_key
                        ...
                    missing_fields -> # If the field is missing then we do something
                        ...
                end # You could then pass all of this to an Enum.map/2 to keep all the fields

            Reduce
                Enum.reduce/3 is probably the most useful of all the Enums as it can do some much.
                    Enum.reduce(
                        enumerable,
                        initial_acc,
                        fn element, acc ->
                        ...
                        end
                    ) # It will follow this syntax

                You can use operators to turn the function into something more concise with &+/2, &*/2
                    Enum.reduce(list, 0, &+/2) # Will add the values of the list.

                Remember that you can always have different conditions (multiclass lambda) for pattern matching with any lambda you write:
                    Enum.reduce(list_with_not_a_number, 0, fn 
                            element, sum when is_number(element) ->
                            sum + element
                            
                            _, sum -> 
                            sum
                            end
                            ) # With this we will always try to make to is_number/1 but if not then we just do nothing with the acc

                With all this being said it is more Elixir to have cleaner code and you might just make a helper function that will be called in the place of the single lambda.

                    defmodule NumHelper do
                        def sum_nums(enumerable) do
                            Enum.reduce(enumerable, 0, &add_num/2)
                        end
                        defp add_num(num, sum) when is_number(num), do: sum + num
                        defp add_num(_, sum), do: sum
                    end # In this way you have a clean function that will still have pattern matching (multiclass)

        3.4.4 Comprehensions
            Denotes another expression that can help you iterate and transform enumerable.
                for x <- list do
                    x*x
                end

            This is great for permutations and things like that. These will iterate through anything that is enumerable. You can add in the into: to make the for a lambda and have it work for anything you put into it:
                multiplication_table =
                    for x <- 1..9,
                        y <- 1..9,
                        into: %{} do # This specifies the collectable
                    {{x, y}, x*y}
                end
                This will populate the entire table for the multiplication_table for the numbers 1..9:
                    Map.get(multiplication_table, {7, 6}) # This will pull the key for the {7,6}

                IF you want to do some more filtering for the list you can then use an other param in the definition.
                    for ...
                    ,...
                    , x >= y # This line will ensure that you only return the values for x and y that work with the check.

                This can also iterate through a binary but the syntax is different

        3.4.5 Streams
            This is a special kind of enumerable tha can be useful for lazy composable operations. Let's say that you want to index and print the list of employees

            First you would Enum.with_index/1 then Enum.each/2 to get the list. The problems here is that you are going through the list twice once for each Enum.

            So there is a few things about stream that we should go over first is that it only creates the stream and nothing else. You will tell it what to do with the stream but you will need to then output it to a list or something you need.
                stream = Stream.map([1, 2, 3], fn x -> 2 * x end) # This created the stream
                Enum.to_list(stream) # This takes the stream and does something to it.

            Now remember that this is a lazy way of doing things it will only do what you ask it for an nothing else. You can use this to your advantage with Enum.take/2
                Enum.take(stream, 1)

            Now back to our example we can use the Stream.with_index/1 and knowing how the index is written you can iterate the entire list with some small changes.
                employees
                |> Stream.with_index()
                |> Enum.each(fn {employee, index} -> 
                    IO.puts("#{index + 1}. #{employee}")
                end) # Very elegant solution to the problem

            You can do a lot with this and continue to pass more and more into the Stream as needed.
                [9, -1, "foo", 25, 49]
                |> Stream.filter(&(is_number(&1) and &1 > 0))
                |> Stream.map(&{&1, :math.sqrt(&1)}) 
                # This was the hardest to get my head around as you are making a concise lambda and then taking 
                # the first argument to create a tuple with the number and sqrt.
                |> Stream.with_index()
                |> Enum.each(fn {{input, result}, index} ->
                    IO.puts("#{index + 1}. sqrt(#{input}) = #{result}")
                end)

            Keeping in mind the syntax and format of the output of each function. This is also done in a single pass for each element of the list not running through it every time a new Enum is done.

            There is also the file stream to go through each line of a file one at a time WITHOUT putting the entire file into memory.
                def large_lines!(path) do
                    File.stream!(path)
                    |> Stream.map(&String.trim_trailing(&1, "\n"))
                    |> Enum.filter(&(String.length(&1) > 80))
                end
            
            Infinite Streams
                What about infinite streams Stream.iterate/2 can come in here. This one will just continue to iterate over the function that you pass it

                Stream.repeatedly/1 will work just as above but is meant to go through a file or stream.

    Practice Exercises
        Again see the pages that I add to the folder

Chapter 4 Data Abstraction (112)
    Instead of classes you use modules, also remember that Elixir is immutable so you will always have to rebind the output into the same or an other variable. They might be modifiers and they might be query function but they usually will take and return the same value types.

    4.1 Abstracting with Modules
        So without going into the schemaless you can abstract a new data type with the MapSet.new() and MapSet.put/2

        4.1.1 Basic Abstraction
            `D[] is the syntax for a date type
            While we are trying to create a todo-list we want to have a special module for just the todo-list.

            You can create a new list with the def new, do: %{} 

            Then once you have the date and title you can add in the update/add functionality

            Once that is done you can add the get_entries based off a date. Keep in mind that this will not store the data within anything you must pass the map to the function after binding it.

        4.1.2 Composting Abstractions
            You can always take some of the code and move it to an other module. In this way (with the proper naming)  things will looks more clear. LIke in the example you will create a function/module that will take the add/remove lookup and make it their own functions.

        4.1.3 Structuring Data with Maps
            Now keep in mind with the above you are manually hardcoding the date to add to the todo, if you were to want to change the entry to an other date type you will break the functionality. What if there was a way to pass everything all at once and then get the information from that item.

            This is were Maps can help again. Put everything into a map and use the (.) notation to pull the information that you need.

        4.1.4 Abstracting with Structs
            With this example we will be trying to deal with fractions. When dealing with a struct you want to use this syntax:
                defmodule Name do
                    defstruct a: nil, b: nil
                    ...
                end

            And to invoke the new struct:
                %Name{$info goes here}

            One thing to keep in mind is that you can pattern match a struct to a struct but a struct is NOT a map.
            You can add or update a struct like a map:
                struct = %Name{other_struct | b: 4} # assuming that b is a valid key.

            Check out the module that I created for this but you can always use the (.) notation to decompose the fields

            Structs vs Maps
                One thing to keep in mind is that you can't Enum a struct they are special.
                But you can use the Map module in the same way with Structs. Weird thing here is that a Map can match a struct, but a struct can't match a map. This is because to match to a struct you must have all the fields present and the struct has the __struct__ and the name in the field.

            Records
                defrecord and defrecordp 

        4.1.5 Data Transparency
            Data is almost never hidden within Elixir. You will have everything out in the open unless you take away some of the functionality. Most of the outputs will have some flare attached to it from the way the functions return values. The IO module has an inspect that will show more raw data.

            Also keep in mind that the return value of an inspect will always be the thing that is sent to the inspect. So with label: and piping you can debug more easily.

    4.2 Working with Hierarchial Data
        We want to add CRUD support.

        4.2.1 Generating IDs
            To do this we need to do 2 things:
                Represent the to-do list as a struct as we have more information in the struct ID and the entry
                Use the entries ID as the key

            See the module that I added.

            If you want to get all the values from a Map you can use the Map.values/1

        4.2.2 Updating Entires
            first you look up the id with Map.fetch/2 then you update with the lambda that we pass into the function.

        4.2.3 Immutable Hierarchial Updates
            1 You take the target entry into a separate variable.
            2 You call the updater that returns the modified version of the entry to you.
            3 You call Map.put to put the modified entry into the entries collection.
            4 You return the new version of the to-do list, which contains the new entries
            collection.

            So as this is Hierarchial data you can't just update any part of the data you must walk down the tree to get to the place that you want to change create a copy and then change what needs to be changed.

            Provided Helpers
                Kernel.put_in/2 is a macro that allows you to get to the right place and change a value.
                You will need to use [] and (.) notation to get to the proper place but once there you will be able to change values. Again this is immutable so you must bind the new struct or map.

            Deleting an Entry
                You will need to get to the location then Map.delete\2
        
        4.2.4 Iterative Updates
            So now we want to add in a bunch of new todos in one function call. It is not that tough as long as we can set the map for the entires in one swoop. Let's use the Enum.reduce/3

            We have the functionality for the add_entry/2 already we just need to keep updating the todo_list in the reduce. Remember that you can have ANYTHING for the acc.

        4.2.5 Exercise: Importing from a file.
            See the supporting page for the things that I came up with but it works just not with the stream. 
            Going to create a new one that will work with the stream.

    4.3 Polymorphism with Protocols
        So when building programs you will need to work with functions that will do different things based on what is passed to them this is the idea with Polymorphism. Each time you use an Enum you are asking it to look at what is being passed and then do something different.

        4.3.1 Protocol Basics
            This is a module in which you declare functions without implementing them. Let's look at the String.Chars
                defprotocol String.Chars do
                    def to_string(term)
                end
            
            You can then pass things that can be represented as a string to this function. There are helper functions that Elixir uses as alias, like, to_string etc. What is nice about this is that it will determine the why it is run at RUNTIME.

        4.3.2 Implementing Protocol
            once you have the basic idea about how to create a protocol you can then start to work with defining what happens when you call it with different data types.

            You can use the following syntax for this as well.
                defimpl String.Chars, for: Integer do
                    def to_string(term) do
                        Integer.to_string(term)
                    end
                end
            As you can see we are setting what the String.Chars does for the integer data type. Keep in mind that you can pass any to the for: to have a fall back function. Keep it at the end so that it doesn't get triggered at all times. Also looking below you can implement this for ANY data type.

                defimpl String.Chars, for: TodoList do
                    def to_string(_) do
                        "#TodoList"
                    end
                end

            What is crazy here is that you can place this anywhere in your code and it will still try to implement the things that you pass to it.

        4.3.3 Built-In Protocols
            Elixir comes with some predefined protocols. While many functions have some good use to change, you can do things with the Inspect!!! to change how it prints for any given type. One of the most powerful will be the Enum. These are closely related to the Collectable Protocol.

            Take a look at the todo.ex and see the end. This is taking the collection protocol and making sure that when you see a TodoList and an Enum.into/1 you will go through the list and replace the simple into function with something that will add each item into your TodoList struct.

    Summary
         A module is used to create an abstraction. A module’s functions create, manipulate, and query data. Clients can inspect the entire structure but shouldn’t rely
        on its shape.
         Maps can be used to group different fields together in a single structure.
         Structs are special kinds of maps that allow you to define data abstractions
        related to a module.
         Polymorphism can be implemented with protocols. A protocol defines an inter-
        face that is used by the generic logic. You can then provide specific protocol
        implementations for a data type.

Part 2 Concurrent Elixir
    Now we get to learn about concurrency

Chapter 5 Concurrency Primitives (141)
    5.1 Concurrency In BEAM
        Fault Tolerance
        Scalability
        Distribution

        While going through this chapter be sure to understand that Process is not an OS process as they are more bulky and BEAM Process will be lighter. There is a built in event handler that takes care of the Distribution. BEAM will use as many schedulers as there are physical Cores in your machine.
        Each Process (handled by the scheduler) take microseconds to start and has a very small memory presence. 
    
    5.2 Working with Processes
        Let's assume that you want to run some long queries, that take 2 seconds a piece. IF you want to run them one after the other it should take 10 seconds.

        5.2.1 Creating Processes
            To create a process we need to use the function spawn/1, to keep track of the process that is running the spawned VM you will have a PID assigned.
            async_query = # This function will take the param
                fn query_def -> # Pass it here
                    spawn(fn ->
                    query_result = run_query.(query_def) # Then pass it here to be run with the lambda above
                    IO.puts(query_result)
                    end)
                end

                async_query.("query 1")

            Let's take a look at this as it shows a few things that you should need to know. Looking at the comments we see that we are passing the information down through the tree and it will need to be copied deeply as processes can't share and information.
                Enum.each(1..5, &async_query.("query #{&1}")) # This will return all 5 at one time. because it will call the spawn 5 times asynctly.

        5.2.2 Message Passing
            There will be times that you want to do basic calculation within many processes and then pass all the data to a higher process to do the rest of the work. We will use messages here to take care of this.
                receive do
                    pattern_1 -> do_something
                    pattern_2 -> do_something_else
                end

                send(pid, {:an, :arbitrary, :term})

            These messages will be processed in the FIFO pattern and can and will only be limited by the memory of the system. Looking at he above we can still pattern match if we want. Keep in mind that you must pattern match to the block of code and you must have a message in order for the receive to work. There is a block that you can use to be sure that something happens:
                receive do
                    message -> IO.inspect(message)
                after
                    5000 -> IO.puts("message not received")
                end

            Receive Behavior
                SO there are a few cases where a failed pattern match will not fail and will not raise an error and receive is one of them. It will simply move on to the next message and put the fail message at the end of the queue.
                    1 Take the first message from the mailbox.
                    2 Try to match it against any of the provided patterns, going from top to bottom.
                    3 If a pattern matches the message, run the corresponding code.
                    4 If no pattern matches, take the next message, and start from step 2.
                    5 If there are no more messages in the queue, wait for a new one to arrive. When
                    a new message arrives, start from step 2.
                    6 If the after clause is specified and no message is matched in the given amount
                    of time, run the code from the after block.

                Remember that EVERYTHING has a return value and the receive is no different it will return the last line before the end break.

            Synchronous Sending
                This uses the "Fire-and-forget" method and will not care about whether the receiver got or processed the message, in order for both parties to know what is happening you have to specify what you need. You can do it with an other send()/2 but then both parties need to know what to do as well as have a need for this.

                You will need to send the caller PID in order to get a call back.
                    send(pid, {self(), some_message}) # Self here is the PID
                    receive do
                        {:response, response} -> ...
                    end

            Collecting Query results
                Now we want to store all the messages into one main process.
                async_query =
                    fn query_def ->
                        caller = self() # Stores the Pid in the main calling process

                        spawn(fn ->
                        query_result = run_query.(query_def)
                        send(caller, {:query_result, query_result}) # Sends a response
                        end)
                    end

                Enum.each(1..5, &async_query.("query #{&1}")) # Sends the 5 messages, but nothing the main process does changes.

                get_result = # Create a lambda to receive the messages
                    fn ->
                        receive do
                        {:query_result, result} -> result
                        end
                    end

                    results = Enum.map(1..5, fn _ -> get_result.() end) # Store the messages into a list.

    5.3 Stateful Server Process
        The idea that you might want to create a long-running process that can server various requests. This is stateful sever process.

        5.3.1 Server Processes
            A server process is an informal name for a process that runs for a long time (or forever). In order to achieve this you will need to run tail recursion (to reduce the memory and CPU needed)

            defmodule DatabaseServer do
                def start do
                    spawn(&loop/0) # Starts the process
                end

                defp loop do
                    receive do # receives a message
                    ...
                    end

                    loop() # Continues the loop.
                end

                ...
            end

            It is standard to put the entire code for the process into it's own module and have 2 types of functions within:
                interface (public) and implementations (private) I will put the code here as well but make sure to check out the additional Chapter 5 livebook. Things to keep in mind is that you want to wrap all the message passing within helper functions that will make sure that the client will not see all the way you pass messages. You will also want to wrap any query so that you can make it easier to parse the issues that you might see within the code.

            Server Processes are Sequential
                Everything within a server is done one at a time. This can be helpful if you want to understand a bug or the process. With that being said you can do more at the same time by creating a pool of processes. 
                    pool = Enum.map(1..100, fn _ -> DatabaseServer.start() end) 
                    # This will create a list of 100 process (with PID) stored so you can access any of them

                    You then need to pick a process to do the work. 
                    Enum.each(
                        1..5,
                        fn query_def ->
                            server_pid = Enum.at(pool, :rand.uniform(100) - 1)
                            DatabaseServer.run_async(server_pid, query_def)
                        end
                    ) # This is not efficient as the process of choosing takes O(N) and you might send the same one more than 1

        5.3.2 Keeping a Process State
            You will need at times to keep data within the state and as such you will need to continue to pass the state with the loop here is the standard process for that:
                def start do
                    spawn(fn ->
                        initial_state = ... # sets the state that will be used.
                        loop(initial_state)
                    end)
                end
                defp loop(state) do
                    ...
                    loop(state) # keeps the state
                end

            We can then use this to change our DatabaseServer to keep and pass a state.
            def start do
                spawn(fn ->
                connection = :rand.uniform(1000)
                loop(connection)
                end)
            end

            after we set the loop and the start to include the state it is a simple matter to make sure the state is sent with it: 
                In this case we are using the start to make a connection to a random pid (not actually but pretending that)
                Then passing the state to the loop.
                The loop will wait for a message from a "User"
                The user can then use the run_async to pass the pid and the "query"
                The run_async will then send the message to the server (with the helper function) that will describe the query
                The run_query will then do the "query" and then hold the message within the stack
                The user can then receive the message from the stack with the get_result 

        5.3.3 Mutable State
            We want to create a calculator that will hold the current value within the state and the a user can get to the value with a get.
            
            Let's look at the inner loop first
                def loop(current_value) do
                    new_value =
                    receive do
                        {:value, caller} ->
                        send(caller, {:response, current_value})

                        {:add, value} ->
                        current_value + value

                        {:sub, value} ->
                        current_value - value

                        {:mul, value} ->
                        current_value * value

                        {:div, value} ->
                        current_value / value

                        {:clear, _} -> current_value = 0

                        invalid_request ->
                        IO.puts("invalid request: #{inspect(invalid_request)}")
                        current_value
                    end

                    loop(new_value)
                end

            This is pretty simple as all we are doing is setting the new_value based off of what we received from the current state and the atom that tells us the operation to do

            Next lets set the value function. and the functions that will do the Arithmetic.
                def value(server_pid) do
                    send(server_pid, {:value, self()})

                    receive do
                    {:response, value} ->
                        value
                    end
                end

                def add(server_pid, value), do: send(server_pid, {:add, value})
                def sub(server_pid, value), do: send(server_pid, {:sub, value})
                def mul(server_pid, value), do: send(server_pid, {:mul, value})
                def div(server_pid, value), do: send(server_pid, {:div, value})

            Again pretty simple as we will need a function that will send the current_value and functions that will send the right message to the server.

            Now that we have this all setup we can then do something to the loop to make it more concise while adding in a help function to process the message.
                defp loop(current_value) do
                    new_value =
                    receive do
                        message -> process_message(current_value, message)
                    end

                    loop(new_value)
                end
                

                defp process_message(current_value, {:value, caller}) do
                    send(caller, {:response, current_value})
                    current_value
                end

                defp process_message(current_value, {:add, value}), do: current_value + value
                defp process_message(current_value, {:sub, value}), do: current_value - value
                defp process_message(current_value, {:mul, value}), do: current_value * value
                defp process_message(current_value, {:div, value}), do: current_value / value
                defp process_message(current_value, {:clear, value}), do: 0

            This one will take the same logic for the response and turn it into one set of logic that will use the process_message to do the work
        
        5.3.4 Complex States
            What if we want to keep and update a TodoList for the state of the server. First we need to put both the TodoList and the new TodoServer into the same module and then implement all the function that we need.

            Keep in mind that we will need a public function that a user can use to do and action and then a private function that will pass the data and the pid so that we can add things to the stack and process them.
                def add_entry(todo_server, new_entry) do
                    send(todo_server, {:add_entry, new_entry})
                end
                ...
                defp process_message(todo_list, {:add_entry, new_entry}) do
                    TodoList.add_entry(todo_list, new_entry)
                end
            
            Concurrent vs Functional Approach
                You will find that in the end you will want to have a separate server for each of the instances of a data structure. That way you will be able to keep them Concurrent and be able to scale. Think of it this way you should try to model the changes to the data as a functional approach while the overlying state should be done with processes.

        5.3.5 Registered Processes
            In order to talk to an other process you will need to know the PID, so in order for process A to talk to Process B you will need to bring the PID for B to process A.

             For this there is a special function under the Process module Process.register(pid, name)
                The name can only be an atom
                a single process can have only 1 name
                two process can not have the same name

            Look at the Chapter5 for the livebook to see the implementations for this type of function.
            Couple things to go over here. The Process.register(self(), :name) must be done before you spawn a new process within the start, once that is done you no longer need to pass the PID but simply pass the :name. 

            If you need to kill a process you can use:
                Process.whereis(:todo_server) |> Process.exit(:kill)

            Once you start a server you will need to not try and start it again as it will have an issue with the name already being taken. While in live book I used this logic to keep it from freaking out.
                def start do
                    spawn(fn ->
                    # Only register if not already taken
                    unless Process.whereis(:todo_server) do
                        Process.register(self(), :todo_server)
                    end

                    loop(TodoList.new())
                    end)
                end
    
    5.4 Runtime Considerations
        Let's talk about runtime properties
        
        5.4.1 A Process is Sequential
            Looking at the example you can see that you will be able to spawn the process to send messages but the single server will run into issues send responses. You can see if the number of servers was very high you would have a bottle neck. What can you do? try to optimize the response times for the single response server.

        5.4.2 Unlimited Process Mailboxes
            No lets think about the idea that a mailbox will continue to grow if the messages are not received or pattern matched correctly. (YOu should always have a default pattern match).

            defp loop
            receive do
                {:message, msg} -> do_something(msg)
                # add this to pattern match a default other -> warn_about_unknown_message(other)
            end
                loop()
            end

        5.4.3 Shared-Nothing Concurrency
            Nothing is shared between processes. So when you send a message the entire thing is deep copied.

        5.4.4 Scheduler Inner Workings
            Most of the time you will have n processes and m tasks run by the n process in most cases m > n this called m:n threading. 

            You will normally run process equal to the number of cores on your system but that can be changed with 
                iex --erl "put Erlang emulator flags here"

                $ iex --erl "+S 1"
                Erlang/OTP 26 [erts-14.0] [source] [64-bit] [smp:1:1] [ds:1:1:10]

                iex(1)> System.schedulers()
                1

    Summary
     A BEAM process is a lightweight concurrent unit of execution. Processes are
    completely isolated and share no memory.
     Processes can communicate with asynchronous messages. Synchronous sends
    and responses are manually built on top of this basic mechanism.
     A server process is a process that runs for a long time (possibly forever) and
    handles various messages. Server processes are powered by endless recursion.
     Server processes can maintain their own private state, using the arguments of
    endless recursion.

Chapter 6 Generic Server Processes (173)
    Let's learn about OTP (Open Telecom Platform)
    
    6.1 Building a Generic Server Process
        Here we want to:
            spawn a separate process
            Run an infinite Loops
            Maintain a process state
            react to messages
            send a response back to the caller

        6.1.1 Plugging in with modules
            Generic code vs the concrete version you will end up with. In order to do this you will use modules. Remember that a module name is an atom and as such you can bind it to a variable and use the variable to call it.

            some_module = IO
            some_module.puts("hello")

        6.1.2 Implementing the Generic Code
            With the code in the livebook Chapter_6 we have the star that will use the init. 
            then start the loop
            the return value of the spawn will be a pid.

            With the loop implementation we can go over it.
                The loop waits for a message of the format {request, caller}
                Then sends the response to the caller
                then restarts the loop.

            Now we need to be able to send a request to the server (as a user they will need to use a call/2 function). We use call in this case as we want to receive a response.
        
        6.1.3 Using the Generic Abstraction
            Now that we have the server setup you want to be able to have a callback function that will handle the data that we send and receive.

            Now we can further obfuscate the process by adding in more helper functions. We are trying to remove the user knowing anything about the server. In this case we want to only have the KeyValueStore as the user interface. 

            Now we can use start/0 put/3 and get/2
                KeyValueStore.start()/0
                So the KeyValueStore will start a new Process
                
                Then the KeyValueStore.put()/3:
                will call ServerProcess.call()
                Then it will send a call to ServerProcess that will be of the form {request, caller(self())}
                The loop will receive that and send the request to the KeyValueStore using handle_call()/2
                It will process the :put from the list of handle call
                Which will {:ok, Map.put}
                
                Then when we use the KeyValueStore.get()/2:
                invoking the get from KeyValueStore
                which calls the ServerProcess PID with {:get, key}
                which sends the request (:get) to the ServerProcess
                The loop takes over and then sends that request (:get) to the callback function
                which then will {Map.get(state, key), state}

        6.1.4 Supporting asynchronous Requests
            Call is used for Synchronous requests as it wants a response, cast is used when we don't need a response.
            We added an extra bit to the send message and the call as now we need to be able to handle a call or a cast

        6.1.5 Exercise: Refactoring the Todo-Server
            Okay so let's go over this as it was a bit of a struggle to figure this whole thing out. 
            First we wanted to start a ServerProcess with the TodoServer

            Second we needed to create 2 functions that will do the work for each action that we want handled.
            get() (entries)
                this will make the call to the Server that will ask for the entries that match the date.
            handle_call ({:entries, date}, state) 
                This will actually take the todo_list and perform the action

            put() (add_entries)
                This will make the call to the server that will do the work on the state
            handle_cast({:add_entries, entries}, state)
                This will actually perform the action to the state and update it.

            We wanted to keep as much of the underlying support away from the user so we need helper functions for each step
    
    6.2 Using GenServer
        Here are some of the benefits of a GenServer:
            Support for calls and casts
            Customizable timeouts for calls
            Propagation of server process crashes
            Support for Distributed Systems

        6.2.1 OTP Behavior
            Behavior is generic code that implements a common pattern. 
            Here are some of the standard libraries for Behavior in OTP:
                 gen_server—Generic implementation of a stateful server process
                 supervisor—Provides error handling and recovery in concurrent systems
                 application—Generic implementation of components and libraries
                 gen_event—Provides event-handling support
                 gen_state—Runs a finite state machine in a stateful server process

        6.2.2 Plugging into GenServer
            When we: use GenServer, there is functions that are injected into the module from compilation. 

        6.2.3 Handling Requests
            Now we want to implement the same server using GenServer (See livebook)
            Couple things to go over:
                init takes 1 argument and it is the second param of the GenServer.start/2
                init requires the last line to be of the form {:ok, initial_state}
                handle_cast needs to be of the form {:noreply, new_state}
                handle_call needs to be of the form {:reply, response, new_state}
                    response is usually a tuple with ID and and the PID of the caller.

            With the general boilerplate out of the way we need to define the helper functions to allow a user to send and receive messages.

        6.2.4 Handling Plain Messages
            Messages contain more than just the message they also include some payload to know what to do.
            :timer.send_interval/2 can send a message every x milliseconds this will highjack the handle_info/2 callback to take care of its internals.

        6.2.5 Other GenServer Features
            Here are a few things to go over before we dive deeper
                Compile-Time Checking
                    So when you are building things in GenServer you might find that you are not using the correct version of the function that you are defining. As such if you are about to define a needed function you should denote that its is an @impl which denotes that you are defining a callback function (needed function).

                Name Registration
                    When starting a GenServer it might be helpful to define a name for the process. GenServer.start/3 can help here.
                    GenServer.start(
                        CallbackModule,
                        init_param,
                        name: :some_name
                    )

                    there is also the option of using __MODULE__ in place of :some_name as it will just use the module as the name and you can just use __MODULE__ for any time you would use a PID.

                Stopping the Server
                     {:ok, initial_state} from init/1
                     {:reply, response, new_state} from handle_call/3
                     {:noreply, new_state} from handle_cast/2 and handle_info/2

                    So if you want to stop the server you can run GenServer.stop/2 or you can set as the last result of a call to be {:stop, reason, new_state} (cast) or {:stop, response, reason, new_state} (call)

        6.2.6 Process Life Cycle
            It is important to know what is happening within the process of the GenServer. 
            Client starts with init 
            GenServer init -> init
            Server starts loop

            Client call/cast ect.

            Loop send call to the right functions

            Repeat till end of time or terminate

        6.2.7 OTP-Compliant Processes
            Once you start to build production level code you should avoid spawn and use child parent versions that will be able to deal with some fault tolerance.

    Exercise 6.2.8 GenServer-Powered to-do Server
        See Livebook

    Summary
         A generic server process is an abstraction that implements tasks common to any
        kind of server process, such as recursion-powered looping and message passing.
         A generic server process can be implemented as a behavior. A behavior
        drives the process, whereas specific implementations can plug into the
        behavior via callback modules.
         The behavior invokes callback functions when the specific implementation
        needs to make a decision.
         GenServer is a behavior that implements a generic server process.
         A callback module for GenServer must implement various functions. The most
        frequently used of these are init/1, handle_cast/2, handle_call/3, and
        handle_info/2.
         You can interact with a GenServer process with the GenServer module.
         Two types of requests can be issued to a server process: calls and casts.
         A cast is a fire-and-forget type of request—a caller sends a message and immediately moves on to do something else.
         A call is a synchronous send-and-respond request—a caller sends a message and
        waits until the response arrives, the timeout occurs, or the server crashes.


Chapter 7 Building a Concurrent System (192)
    What happened if you need to more than 1 file for everything. Here you will find how the mix system works.
    
    7.1 Working with the Mix Project
         You should place your modules under a common top-level alias. For example,
        modules might be called Todo.List, Todo.Server, or similar. This reduces the
        chance of module names conflicting when you combine multiple projects into
        a single system.
         In general, one file should contain one module. Occasionally, if a helper mod-
        ule is small and used only internally, it can be placed in the same file as the
        module using it. If you want to implement protocols for the module, you can do
        this in the same file as well.
         A filename should be an underscore-case (aka snake-case) version of the main
        module name it implements. For example, a TodoServer module would reside in
        a todo_server.ex file in the lib folder.
         The folder structure should correspond to multipart module names. A module
        called Todo.Server should reside in the lib/todo/server.ex file.

    7.2 Managing Multiple to-do Lists
        There are two approaches to extending this code to work with multiple lists:
             Implement a pure functional abstraction to work with multiple to-do lists. Mod-
            ify Todo.Server to use the new abstraction as its internal state.
             Run one instance of the existing to-do server for each to-do list.

        7.2.1 Implementing a Cache
            We ended up creating a (basically) whole new project but copying the project into an other todo_cache folder. Once that was done we then created a new module that will take care of the creating and finding of new PIDs for each todo-list.

        7.2.2 Writing Test
            Now we can start to write and test the code. We want to try and write as many test to the server as possible always try and be sure that you are just testing module and functions, try not to test everything at once and you should be able to work with what you have.

        7.2.3 Analyzing Process Dependencies
            Thinking about bottlenecks in the system we have only 1 process to start and find todo-list servers. This could be an issue if the amount of time it take to start (or do the thing we want) take too long.

            Last thing is that if you want to be sure that a list is only modified in sequence then you should be sure that only 1 process is handling it.

    7.3 Persisting Data
        Now we need to talk about making the data persistent so that we can have and load it as we need at a later date.
        7.3.1 Encoding and Persisting
            We will use the :erlang.term_to_binary/1 for some of this exercise.
            File.mkdir_p!/1 will make the folder if it's not already made.
        
        7.3.2 Using the Database
            To use the database you will need 3 things:
                1 Ensure that a database process is started.
                2 Persist the list on every modification.
                3 Try to fetch the list from disk during the first retrieval.

            Storing the Datastore Request
                With the idea that we will need to maintain and retrieve items from the now file on the system we need to change how we implement the code for adding and retrieving as well as be sure that we also send more information to the functions.
                     Todo.Server.start now accepts the to-do list name and passes it to
                    GenServer.start/2.
                     Todo.Server.init/1 uses this parameter and keeps the list name in the process
                    state.
                     Todo.Server.handle callbacks are updated to work with the new state format.                    

                So we start a new TodoServer with the name passed. This can then be kept withing the server state so that we can later use it as a key for the onsite file. It can be error prone but this works for the current setup of our code.

            Reading the Data
                So in this case we are asking the init for the Todo.Database to send a get that will then try and read the file for the input or just use an empty list.
                    Keep in mind that anything that you do within an init must be completed before it can move on to an other process. SO try to keep them succinct. There is a way to break the init into other processes. In that case you must use this syntax:
                        {:ok, initial_state, {:continue, some_arg}}
                        # this is the last line of the init and does these steps:
                         The initial state of the server process is set.
                         The GenServer.start invocation in the caller process is unblocked.
                         The handle_continue callback is invoked in the server process. The callback
                        receives the provided argument (from the {:continue, some_arg} tuple) and
                        the server state.

                    This will then go to the def handle_continue(:init, state) do

        7.3.3 ANalyzing the System
            Okay so right off the bat init must be done synchronous and the casts can be done asynchronous. 
            The get call is also synchronous so that might also be a problem if too many calls come in.
        
        7.3.4 Addressing the Process Bottleneck
            Bypassing the Process
                So what about just not doing a separate process for the database? Well there seems to be 3 reasons to do a separate process:
                    Long-living state
                    Wants to keep some of the invocations and reuse them
                    A critical section of code must be synchronous

                With the current setup yeah we could issue all the Database calls from the Todo_server but if you have too many calls at the same time you will run into issues with too many IO operations that really should be done in sequence.

            Handling Requests Concurrently
                What about sending out the single servers requests into workers? This will work as the worker will finish the process and then it can be ready for an other job. THis runs into issues when you need things to be concurrent. Cast is easy as it will not need a response but for a call you must be able to send a response to the client.

            Limiting Concurrency with Pooling
                An other way is instead of ignoring the server way (put the call in the todo-server), or handling each process by with a worker (todo-database) You can have the database spawn the processes.
    
    7.3.5 Exercise Pooling and Synchronizing
        We wanted to change the database and server to create 3 workers that will handle all the read/writes for the database. For this to work we need:
            The database to create 3 workers and name them with an index that we create.
            The database worker to take the folder as an option as well and not be hardcoded a name
            The database to be able to choose a worker :erlang.phash2/2 is a good function for this
            any call to the database needs to be able to choose a worker so we will need to add that step
            We are no longer just casting right from the database so all calls that would normally just write/read from there must now call the DatabaseWorker instead.
            We need to be sure that we are writing to the /folder/person data so we need a way to create the pathway and then read from it so we needed an helper function to take care of that.

    7.4 Reasoning with Processes
        Try to think of processes as a service that does a single thing that way you can abstract everything out and have a more succinct way of doing things. When things need to communicate you will get into a little bit of trouble but you should be able to reason your way out of it.

    Summary
         When a system needs to perform various tasks, it’s often beneficial to run different tasks in separate processes. Doing so promotes the scalability and fault tolerance of the system.
         A process is internally sequential and handles requests one by one. A single process can, thus, keep its state consistent, but it can also cause a performance bottleneck if it serves many clients.
         Carefully consider calls versus casts. Calls are synchronous and, therefore, block the caller. If a response isn’t needed, casts may improve performance at the expense of reduced guarantees because a client process doesn’t know the outcome.
         You can use Mix projects to manage projects that consist of multiple modules.

Chapter 8 Fault Tolerance Basics (215)
    We want to acknowledge that faults happen but limit the effects it has on your system.

    8.1 Runtime Errors
        Things happening after the code is compiled is a runtime error a type match is one of the most common errors. You could also get a few errors with timeout. Whenever an error occurs it will try and traceback the error to the highest level that could have spawned it.

        8.1.1 Error Types
            errors
            exits
            throws

            raise/1 macro will pass an error, if your function explicitly raises an error append ! to the function name. This should be the case no matter what error is raised so long as you use the raise/1

            exit/1 is an other type of error. This can help you get out of a loop as it will exit the current process. 

            throw/1 is an other type or error. This will throw the value given. As most of the functions and ways of dealing with elixir loops is recursion so if you need to propagate an error all the way to the top throw/1 is a good use case.

        8.1.2 Handling Errors
            There are ofc was to deal with and catch any of these types of errors
                try do
                    ...
                catch error_type, error_value ->
                    ...
                end

            It will do the do block and if an error occurs it will go to the catch block. There is a few examples that we can try with Livebook. See Chapter 8. 
                Within the example the lambda that we made will take a function and process it.

                Also note that the type and value are patterns as well, so you could add pattern matching to the catch block and deal with each differently.

                If you want to catch anything you can use the type, value or _ and it will treat them all the same.

            We can now take care of the "after" block. Which is run after the try block no matter what happens. 

            All this is basic level abstraction, but we can try and boil it down a bit:
                  A run-time error has a type, which can be :error, :exit, or :throw.
                 A run-time error also has a value, which can be any arbitrary term.
                 If a run-time error isn’t handled, the corresponding process will terminate.

    8.2 Errors in Concurrent Systems
        Look at the quick example within the Chapter 8 Livebook. As you can see one of the processes finished and the other raised an error the first wasn't affected by the failed one.

        8.2.1 Linking Processes
            When you are doing anything yeah the processes will not take everything down but if you don't have a strategy to make things come back up your system will not work. This is were linking comes in.

            If one goes down they both do. See the example in Chapter 8

            Trapping Exits
                While it seems that this would be a bad thing as we want decoupled processes, but if you trap an exit you can then not crash the system and the do something about the error.

                The general format of the message is {:EXIT, from_pid, exit_reason} this is different from the general error format of {reason, where}

        8.2.2 Monitors
            Links are normally bidirectional but there are times where you would want to have it only go one way.
            Process.monitor/1 is the way to go here instead of spawn_link/1

    8.3 supervisors
        We now can talk about how to describe what to do when these things happen and what built-in functions are Available to take care of them.
        
        A supervisor is a generic process that manages the life cycle of the other processes in the system. By invoking Supervisor.start_link/2 you are:
            1 The supervisor process traps exits and then starts the child processes.
            2 If, at any point in time, a child terminates, the supervisor process receives a corresponding exit message and performs corrective actions, such as restarting the crashed process.
            3 If the supervisor process terminates, its children are also taken down.

        We want to now add in a supervisor for our todo-code:
             Todo.Server—Allows multiple clients to work on a single to-do list
             Todo.Cache—Maintains a collection of to-do servers and is responsible for their creation and discovery
             Todo.DatabaseWorker—Performs read–write operations on the database
             Todo.Database—Manages a pool of database workers and forwards database
            requests to them

        So in this case the Todo-cache starts the whole process so we want to have a supervisor for this process. 

    8.3.1 Preparing the Existing Code
        So as we have already set the Server Cache DatabaseWorker and Database we only need to make it so the init of the cache will create a link and then name the server so that it doesn't need to be passing the PID.

    8.3.2 Starting the Supervisor Process
        Okay so we made a few changes and then set some IO.puts to keep track of everything that is started.

        Let's go over the Supervisor.start_link/2
            Supervisor.start_link(
                [Todo.Cache], # List of child Specifications
                strategy: :one_for_one # Strategy for the Relationship
            )

        In its simplest for the child Specifications is just the Module that it will check for how to start and what to do.
        The strategy is what happens when there is an issue. one_for_one is when a child goes down you will need to "restart" that child and replace it.

        Couple things here:
            Once the system is up you can interact with it.
                bobs_list = Todo.Cache.server_process("Bob's list")
            We named the cache process so we can now use the name to find its PID
                cache_pid = Process.whereis(Todo.Cache)
            We can now exit the process to see what happens with the parent/child Relationship
                Process.exit(cache_pid, :kill)
            We should see that the process started back up right away also that the PID for the new child is different
                Process.whereis(Todo.Cache)

    8.3.3 Child Specification
        To manage a child process, a supervisor needs some information:
             How should the child be started?
             What should be done if the child terminates?
             What term should be used to uniquely identify each child?

        In normal situations the child_specification would look something like this
            %{
                id: Todo.Cache, # named by the module
                start: {Todo.Cache, :start_link, [nil]}, # Module, start function, params passed
            }

        For our specific example
            Supervisor.start_link(
                [
                    %{
                        id: Todo.Cache,
                        start: {Todo.Cache, :start_link, [nil]}
                    }
                ],
                    strategy: :one_for_one
            )

        This is the normal way of doing it with everything spelled out. There is an other way that will require that you have the start_link set but you can use:
            Supervisor.start_link(
                [{Todo.Cache, nil}],
                strategy: :one_for_one
            )

        THis is because GenServer has a child_spec/1 that will generate the needed info
        You could test this with Todo.Cache.child_spec(nil) # You need to pass the init param

        As I said before you need to:
        use GenServer

        def start_link(_) do # this is the initial function that is called.

        There is one more way to take some more info out of the Supervisor.start_link/2
            Supervisor.start_link(
                [Todo.Cache],
                strategy: :one_for_one
            )
        
        Quick recap before going further:
            1 The new process is started, powered by the Supervisor module.
            2 The supervisor process goes through the list of child specifications and starts each child, one by one.
            3 Each specification is resolved, if needed, by invoking child_spec/1 from the corresponding module.
            4 The supervisor starts the child process according to the :start field of the child
            specification.

    8.3.4 Wrapping the Supervisor
        Ok so at this point we have the process for starting the Supervisor within the code. We could then pass the Supervisor.start_link(...) in order to start the system. BUT... you can just add an other layer of code and then use that to pass the same information to the start_link.

    8.3.5 Using a Callback Module
        Now we have from just above a simple module that will do basically the same thing as the command line however you could turn it into a callback module for the Supervisor Module.

        See the file system withing the supervised.../todo/system.ex

        You might be asking why would this help... We in the end for our code its is just a glorified Supervisor.start_link(...). But what would happen if you needed to do some more things before you started a link, or you wanted to have a more modular approach. This could and should be thought or each time you make a new Supervisor tree.

    8.3.6 Linking all Processes.
        Right now if anything crashes you will in the end lose all track of the previous process and all the data within will be lost. 

        The process for taking care of this is to change all start to start_link() its really that simple as these will noe be part of the Supervisor tree. 

        With this all set up you will never loss a process and whatever you do to the process will be kept.

    8.3.7 Restart Frequency
        Keep this in mind that a Supervisor will not just keep restarting a process. It has a default restart frequency of 3 restarts in 5 seconds.

    Summary
         There are three types of run-time errors: throws, errors, and exits.
         When a run-time error occurs, execution moves up the stack to the corresponding try block. If an error isn’t handled, a process will crash.
         Process termination can be detected in another process. To do this, you can use links or monitors.
         Links are bidirectional—a crash of either process is propagated to the other process.
         By default, when a process terminates abnormally, all processes linked to it terminate as well. By trapping exits, you can react to the crash of a linked process and do something about it.
         A supervisor is a process that manages the life cycle of other processes. It can start, supervise, and restart crashed processes.
         The Supervisor module is used to start supervisors and work with them.
         A supervisor is defined by the list of child specifications and the supervision strategy. You can provide these as the arguments to Supervisor.start_link/2, or you can implement a callback module.

Chapter 9 Isolating Error Effects (239)
    We now know how to create a struct, setup a process to handle them, the boilerplate for sending and receiving messages within the system, adding a supervisor within the system, and how to implement a cache. Now we need to set up how to dynamically create processes and then how to deal with errors (how to isolate them). 
        
    9.1 Supervision Trees
        To deal with errors and contain them we should be working with: processes, links and supervisors.
        9.1.1 Separating Loosely Dependant Parts
            With the todo-list so far we create a working from somewhere within the system so any crash will restart the whole system. We want to be able to dynamically start and restart the system. 

            We need to add the Todo.Database to the Supervisor.start_link()

        9.1.2 Rich Process Discovery
            RIght now the workers for the database are called and their PID's are stored in the Database server. So if we want to have each one restarted and their PIDs kept we need a way to keep the data. 

            To get this done a way of taking care of the PID names should be dynamically named and you could then use that name to get to any new process that is restarted.

            So we need a registry of the names and the ones that are in process and the ones that are not in process. So the process will look like this.
                Server registers a process.
                Client needs to access a process so it will look up the ID in the Registry.
                Restart will check the registry and create a new ID
                Repeat

            Check out the chapter 9 in livebook:
            To do this Elixir has some built-in modules. Registry can be used the function start_link/1 to be specific. It takes a key list of options, the key ones are name: keys: (:unique, :dynamic)
            
            Registry.register(:name_of_registry, {:desired_name, arbitrary_value})
            This is the magic, as it will store any new process within the Registry and keep it as a mapping of the name provided.

            Registry.lookup/2 # Takes the name and the key and returns a list of {pid, value}

            You can now send the process a message with send()

            Keep in mind that in our case the process is a one-off and it will not keep the process and ID within the registry. This is perfect as once you are done (or it crashes you will want to have the name/key back).

        9.1.3 Via Tuples
            A via tuple is a mechanism that allows you to use an arbitrary third-party registry to register OTP-compliant processes

            We have only every started a process via name: some_name but there is an other way by using via tuple {:via, some_module, some_arg}

            You can nest tuples as well, but this case we want to talk dynamically naming and finding the name of the registry.

            See the livebook for the example.
                In this case we are using the via tuple to create a new EchoServer with the id passed to the init with the name coming from the via_tuple/1 function. 

        9.1.4 Registering Database Workers
            Now we want to add the registration to our Todo-list. Be sure to look at the pool_supervision mix project for this one.

            We need to add a new module that will be in-charge of the Registry and be able to store and get the ids for the children.

        9.1.5 Supervising Database Workers
            Okay so now that we have the workers being started and named dynamically we want to set an other supervisor for the workers. As we don't want everything in the system to break if too many workers go down.

            to do this we want to set and other supervisor within the database. As is now we shouldn't need the GenServer part of the database, so we will make changes to that so it only starts the children workers.

            So lots to go over here again see the changes to the pool_supervision mix project.

            Listing 9.6
            We removed all the GenServer from the database. We then made the start_link create 3 workers that will do the work. We then used the private worker_spec/1 get the specs for each child of the database. Where each iteration of the Enum will augment the id by 1 and store it in the map. 
            Listing 9.7
            Now that we have the setup from above we overtook the GenServer.child_spec/1 before now we need to implement it ourselves. 
                def child_spec(_) do
                    %{
                        id: __MODULE__,
                        start: {__MODULE__, :start_link, []},
                        type: :supervisor
                        # This is a new field and the valid types are (:worker, :supervisor) default is
                        # :worker
                    }
                end
            Listing 9.8
            Now we need to deal with the store and get functions as we no longer have the GenServer call and requests.

            They may look the same in some regards but now we need to just choose a key form the pool_size and then use that to choose the worker.

            Now everything is setup in our system to have a supervisor tree.

        9.1.6 Organizing the Supervision Tree
            Within our system we have:
            Todo.system:
                ProcessRegistry:        Database:               Cache:
                                        DatabaseWorker:         Server:

            This is the basic setup that will be able to handle a lot of the errors as they come up. Each level can have errors that don't get fixed and then propagate up and restart the service as needed, which will hopefully be able to restart the lower ones.

            OTP-Compliant Processes
                You will need to deal with some not off the shelf (so far) errors to become OTP-Compliant. SUffice to say that you will deal with those on a later date.

            Shutting Down Processes
                There is options for how to deal with a shutdown within the child specifications. 

            Avoiding Process Restarting
                You can set the child to not restart as you might not be able to get back the connection or something like that. In the end you might want to have them go back up a process and start back from there. restart: :temporary is the way to go here. As this creates a temporary child that will not restart.

            Restart Strategies
                 :one_for_all—When a child crashes, the supervisor terminates all other children and then starts all children.
                 :rest_for_one—When a child crashes, the supervisor terminates all younger siblings of the crashed child. Then, the supervisor starts new child processes in place of the terminated ones.

    9.2 Starting Processes Dynamically
        Now we can work on creating the server dynamically.
        
        9.2.1 Registering to-do Servers
            Look to the new mix project under dynamic_workers:
                We added in the restart: temporary as we don't want to keep restarting the server and then changed the start_link to include a name: via_tuple()

        9.2.2 Dynamic Supervision
            Now we want to be able to create the servers as needed by the users needs (not activated by the users). In this case we will use the DynamicSupervisor/2 instead of the Supervisor module.

            We added in the DynamicSupervisor.start_link/2. This creates the link process but no children 
            We added in the start_child/1 This is called when you need a worker
            We added in the child_spec/1 This is the specification for the child.

        9.2.3 FInding to-do Servers
            Now we need to change the way that the server_process works so that it starts a child when needed and can retrieve the child/pid if you need it.

        9.2.4 Using the Temporary Restart Strategy
            We are trying to implement a no restart strategy for this. As we plan on only restarting if there is a need as they will only be needed if a user needs the information, and will be restated in any case.

        9.2.5 Testing the System
            We can now test the system to see how it works
    
    9.3 "Let it Crash"
        There will be times that you should just start fresh and clean with some good logs. You will give your users a new experience that can stay stable. YOu also allow yourself to keep going back to the same state so you can get the same errors.

        9.3.1 Process That Shouldn't Crash
            Processes that shouldn't crash are called error kernel. Try to keep these as simple as possible and be sure to use try/catch to be sure that you will have a backup for the case of it crashing.

            def handle_call(message, _, state) do
                try
                    new_state =
                        state
                        |> transformation_1()
                        |> transformation_2()
                        ...
                    {:reply, response, new_state}
                catch _, _ ->
                    {:reply, {:error, reason}, state} 
                    # Catches all errors and uses the original state                 
                end
            end

        9.3.2 Handling Expected Errors
            You can even use expected errors as a failing pattern match so that you can crash if you see something that you are not expecting

            If you are trying to write to the system and it fails you should just let it crash asap and avoid trying to more on from there.

        9.3.3 Preserving the State
            So in order to preserve the state after a crash you need to be able to store the state somewhere else (an other process or on the disk). With this being said if you plan on saving to disk you need to be able to keep it as up to date as possible. 

            So any time you perform a mutation you should save to disk. Keep this in mind too if the restart is triggered with a bad state and you write that to the disck you will never be able to restart cleanly. So checks on the data to be written can be a big benefit. 

    Summary
         Supervisors allow you to localize the impact of an error, keeping unrelated parts of the system undisturbed.
         The registry helps you find processes without needing to track their PIDs. This is very helpful if a process is restarted.
         Each process should reside somewhere in a supervision tree. This makes it possible to terminate the entire system (or an arbitrary subpart of it) by terminating the supervisor.
         DynamicSupervisor is used for on-demand starting.
         When a process crashes, its state is lost. You can deal with this by storing state outside the process, but more often than not, it’s best to start with a clean state.
         In general, you should handle unexpected errors through a proper supervision hierarchy. Explicit handling through a try construct should be used only when you have a meaningful way to deal with an error.
            

Chapter 10 Beyond GenServer (267)
    So we know about start and spawn_link but those are not production grade applications of the code and should be avoided. Only Supervisor GenServer and Registry are considered to be able to be OTC compliant. We will now learn about Agent and Task.
    10.1 Tasks
        This will start a process nop take any messages and then complete it and then end. Lets start off with awaited task.
        10.1.1 Awaited Tasks
            So once you have a lambda that will do something you can then use Task.async/1 and then Task.await/1 to relieve the result. This is the basic setup for the process. If the result doesn't come back within 5 seconds it will raise an error, but this is default so you can change that with the options.

            If you want to run more than one async you will need to start them all and them await them all too. What is nice is that once you have your map of queries you can just pipe them from one to the other.
            
            Remember that this is the format for the Task.async(fn -> lambda(_) end)
            Remember that this is the format for the Task.await(task)

            This is an all or nothing process as the Task.async will link the processes that it created so if one fails they all fail.

        10.1.2 Non-Awaited Tasks
            Let's add in some metrics to the to-do list server see the folder todo_metrics.
            So to go over this we created a loop using Task that will start a link and loop, once that is set with the proper syntax you can then simply go to your server and add in the module to the Supervisor tree.
                Todo.System.start_link()

        10.1.3 Supervising Dynamic Tasks
            What about communicating with a remote service? You can start a link that will respond to a service await the response then close shop. Let's look to the Chapter 10 Livebook for this one.

    10.2 Agents
        Agents are similar to GenServe but doesn't have all the bells and whistles, if you can get away with just:
            init/1 handle_cast/2 handle_call/3 it can be replaced with Agent
        
        10.2.1 Basic Use
            Okay so you can use:
            Agent.start_link/1
            Agent.get/2
            Agent.update/2
            Agent.cast/2
        
        10.2.2 Agents and Concurrency
            As you can see here, the agent process is very similar to this. You can pass anything as a message. Even lambda, that is what an Agent does. So in the end you just use a simple task like this.

        10.2.3 Agent-Powered to-do Server
            Okay so now we are going to change the todo server to an agent todo server. Check ou the project under todo_agent

            Couple things to add here so that we can understand why Agents are good but always the best use case. First the state of the Agent is open, with GenServer you are using well defined helper functions to let the end user do the work and all the @impl functions are kept behind those calls.  Also Also GenServer has more functionality for the general use cases that you might find.

        10.2.4 Limitations of Agents
            With the current todo-list everything that is created is kept within the cache until the process that spawned it is killed. We want to add in some expiry of the to-do servers so that we can free up space as needed. 

            We are going to implement a way for the process to decide on its own when it needs to be killed and an Agent can't tdo that. See todo_cache_expiry mix project. To do this we need to:
                1 Convert the implementation of the to-do server back to GenServer.
                2 Include the idle timeout integer in all result tuples of all callback functions.
                3 Add handle_info/2 and stop the server if the :timeout message arrives.

            For most of the first step 10.5 we are just adding in the @expiry_idle_timeout to the last line of each @impl this will tell the server when to look at the time since last call. 

            init is a bit different as you will need to include the {:continue, :init} This is because you can't do both the continuation and the and the timeout. handle_continue will be called no matter what on init and thus the timeout will be called and restart the timer.

            Let's look at how we stop the server 10.6
            Pretty simple for the implementation as you just need to declare a handle_info and set the event to :kill

            Also as this is a thing that needs GenServer in most cases its better to start off with GenServer and convert if you need.

    10.3 ETS Tables
        ETS (Erlang Term Storage) ables are a mechanism that allows you to share some state between multiple processes in a more efficient way.

        The best use of these, although you will get a better performance from them will be:
            shared key-value structures
            counters

        For a simple example and module see the Livebook for chapter 10.
        If you use their implementation from the folder key_value they add in some tests.

        But the crux of the issues is that no matter what you are running a single KeyValue server and it will bottle neck.

        10.3.1 Basic Operations
            ETS tables have some unusual characteristics
                 There’s no specific ETS data type. A table is identified by its ID (a reference type) or a global name (an atom).
                 ETS tables are mutable. A write to a table will affect subsequent read operations.
                 Multiple processes can write to or read from a single ETS table. Writes and reads might be performed simultaneously.
                 Minimum concurrency safety is ensured. Multiple processes can safely write to the same row of the same table. The last write wins.
                 An ETS table resides in a separate memory space. Any data coming in or out is deep copied.
                 ETS doesn’t put pressure on the garbage collector. Overwritten or deleted data is immediately released.
                 An ETS table is deeply connected to its owner process (by default, the process that created the table). If the owner process terminates, the ETS table is reclaimed.
                 Other than on owner-process termination, there’s no automatic garbage collection of an ETS table. Even if you don’t hold a reference to the table, it still occupies memory.

            Check out the chapter 10 Livebook for some examples.
            Just going to put these here as they are some possible options for the ETS Table.
                 :set—This is the default. One row per distinct key is allowed.
                 :ordered_set—This is just like :set, but rows are in term order (comparison via the < and > operators).
                 :bag—Multiple rows with the same key are allowed, but two rows can’t be completely identical.
                 :duplicate_bag—This is just like :bag, but it allows duplicate rows.

            Here are some options for the table in general about read/write
                 :protected—This is the default. The owner process can read from and write to the table. All other processes can read from the table.
                 :public—All processes can read from and write to the table.
                 :private—Only the owner process can access the table.

            10.3.2 ETS-powered key-value Store
                Look to the chapter 10 livebook
                As with most things start with a GenServer and then scale back to a ETS table.

            10.3.3 Other ETS Operations
                So there is a lot of other built-in functions you can even traverse the list with first/1 and next/2 but these are not going to be serialized unless you set them to be.

                Let's go over some other things that are Elixir-esque

                Match Pattern
                    See the chapter 10 livebook
                    You can pattern match very easily with this setup
                
                Other Use Cases for ETS
                    Managing server wide shared state is one of the most common use cases for ETS

                Beyond ETS
                    Mnesia is an other embedded database in Elixir
                     Mnesia is an embedded database—it runs in the same BEAM instance as the rest of your Elixir/Erlang code.
                     Data consists of Erlang terms.
                     Tables can be in memory (powered by ETS) or disk based (powered by DETS).
                     Some typical database features are provided, such as complex transactions, dirty operations, and fast searches via secondary indexes.
                     Sharding and replication are supported.

    10.3.4 Exercise: Process Registry
        We want to implement this
            iex(1)> SimpleRegistry.start_link()
            {:ok, #PID<0.89.0>}
            iex(2)> SimpleRegistry.register(:some_name)
            :ok
            iex(3)> SimpleRegistry.register(:some_name)
            :error
            iex(4)> SimpleRegistry.whereis(:some_name)
            #PID<0.87.0>
            iex(5)> SimpleRegistry.whereis(:unregistered_name)
            nil

        Please head to the Livebook for chapter 10 for this one.


    Summary
         Tasks can be used to run OTP-compliant concurrent job processes.
         Agents can be used to simplify the implementation of processes that manage some state but don’t need to handle any plain messages.
         ETS tables can be used to improve performance in some cases, such as shared key–value memory structures.

Chapter 11 Production (295)
    Now we want to be able to use third-party libs and be able to produce production level applications.

    11.1 OTP Applications
        An OTP application is a component that consists of multiple modules and that can depend on other applications. 

        11.1.1 Creating Applications with the mix Tool
            An application resource file is: a plain-text file written in Erlang terms that describes the application. It can contain:
                 The application name and version, and a description
                 A list of application modules
                 A list of application dependencies (which must be applications themselves)
                 An optional application-callback module

            This is in a sense the set of libs that will be called and its in the mix.ex We are going to spend some time in many different folders to create what we want here. Every project started with mix will have this file. It should describe the project, describe the application, and list the dependencies.

        11.1.2 The Application Behavior
            The critical part of the mix.exs is the mod: {HelloWorld.Application, []} This is what tells it what module to use to start the application. At minium it will need to define start/2, this will start the top level process

        11.1.3 Starting the Application
            mix will start the application if you invoke the mix or something similar. Application.start/1 Application.stop/1 can be used to stop the top level process try to be sure that every child is part of or started by the top level process to ensure that everything is stopped properly. There is also System.stop/0 that will stop everything within the entire process.

        11.1.4 Library Applications
            You don't need to provide the mod: ... 
            This will be a application that doesn't have a top level process. This might be best used for library applications that will not need to be supervised but will still need to be started.

        11.1.5 Implementing the Application Callback
            We are now going to take the todo and turn it into an application. To do that we will make an other folder (todo_app) and copy the latest version.

        11.1.6 The Application Folder Structure
            Mix Environments
                There are normally 3 types of Environments that mix will use: dev, test, prod. You can use them as you need and you can introduce your own at any time.

                When you invoke mix test you are switching environments and as such will have a different set of rules applied to the code. When you want to switch manually you can invoke the MIX_ENV=name before the call to start the application.

            The Compiled Code Structure
                complied binaries reside ih the _build/project_env this is where your different set of ENV reside so you can swap.

                The basic folder structure will follow
                    YourProjectFolder
                    _build
                        dev
                            lib
                                App1
                                    ebin
                                    priv
                                App2
                                ... 

                In this way you will always know where to put things.

    11.2 Working with Dependencies
        You will need to add more and more dependencies to help you with larger and larger projects

        11.2.1 Adding a Dependency
            We will add in the poolboy library. for this you will need to go into the mix.exs and go into the deps definitions.
            The dependencies are a tuple with the name and the version number. Once that is set you need to run mix deps.get to retrieve the libraries.

        11.2.2 Adapting the Pool
            You need a pool manager and then once they are set the processes can ask for PID's with checkout and then when done with a worker you can notify the pool manager with checkin

            With this lets adopt the new way of doing things. First we need to start the pool manager, instead of invoking the :poolboy.start_link we can just use the :poolboy.child_spec/3

            See the todo_poolboy project. 

            Next we need to augment how we get the IDs and store them as well.
            
            Then finally we need to augment the DatabaseWorker to not need as much information. 

        11.2.3 Visualizing the System
            Now that we have the full OTP application we can now use observer to see it in action. :observer.start()

            So I wanted to be able to use the built in version of the :observer but that didn't seem to work withing the VsCode terminal.

            I installed this
            defp deps do
                [
                    {:observer_cli, "~> 1.7"}
                ]
            end

            And then used :observer_cli.start() to start an in terminal window.

            I will not try to do the same within the WSL terminal.

    11.3 Building a Web Server
        